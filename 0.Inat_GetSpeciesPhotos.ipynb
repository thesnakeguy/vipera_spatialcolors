{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-GhouIbyjl_"
   },
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pHnqp4i1l4Oz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from pyinaturalist import *\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from typing_extensions import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: get place code for limiting search spatially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m{\u001b[0m\n",
      "    \u001b[1;36m6753\u001b[0m: \u001b[32m'France'\u001b[0m,\n",
      "    \u001b[1;36m10577\u001b[0m: \u001b[32m'ÃŽle-de-France'\u001b[0m,\n",
      "    \u001b[1;36m11367\u001b[0m: \u001b[32m'Fort-de-France'\u001b[0m,\n",
      "    \u001b[1;36m104968\u001b[0m: \u001b[32m'Francesti'\u001b[0m,\n",
      "    \u001b[1;36m30178\u001b[0m: \u001b[32m'Seine-Saint-Denis'\u001b[0m,\n",
      "    \u001b[1;36m38738\u001b[0m: \u001b[32m'Fort-de-France'\u001b[0m,\n",
      "    \u001b[1;36m99548\u001b[0m: \u001b[32m'Hauts-de-Seine'\u001b[0m,\n",
      "    \u001b[1;36m99550\u001b[0m: \u001b[32m\"Val-d'Oise\"\u001b[0m,\n",
      "    \u001b[1;36m99546\u001b[0m: \u001b[32m'Val-de-Marne'\u001b[0m,\n",
      "    \u001b[1;36m30182\u001b[0m: \u001b[32m'Yvelines'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = get_places_autocomplete(q='France')\n",
    "pprint({p['id']: p['name'] for p in  response['results']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdGOwyfxvvHX"
   },
   "source": [
    "# Initialize function to scrap images from Inaturalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1737719532758,
     "user": {
      "displayName": "Pablo Deschepper",
      "userId": "11062026878236535060"
     },
     "user_tz": -60
    },
    "id": "2eI96jmOl92k"
   },
   "outputs": [],
   "source": [
    "# Scrape Images and Metadata\n",
    "\n",
    "# Here we make a function to save photos of a target species locally and save necessary metada: latitude, longitude, observation ID, photo IDs, Photo urls. Metadata is saved as a dictionary and photos are saved in a directory specified by the user.\n",
    "# Metadata example:\n",
    "# observation_id   latitude  longitude    photo_ids  \\\n",
    "# 0       259323505  57.736160  10.629406  [465488543]\n",
    "# 1       259193935  48.037273  11.509971  [465220887]\n",
    "# 2       258982331  49.385485  19.790977  [464790765]\n",
    "# 3       258835093  46.517517   9.908752  [464493974]\n",
    "# 4       258811645  52.674268   6.516881  [464445739]\n",
    "#\n",
    "#                                               photos\n",
    "# 0  [https://inaturalist-open-data.s3.amazonaws.co...\n",
    "# 1  [https://inaturalist-open-data.s3.amazonaws.co...\n",
    "# 2  [https://static.inaturalist.org/photos/4647907...\n",
    "# 3  [https://static.inaturalist.org/photos/4644939...\n",
    "# 4  [https://static.inaturalist.org/photos/4644457...\n",
    "\n",
    "# Parameters\n",
    "output_dir = \"drive/MyDrive/Colab Notebooks/SnakeMorphs/source_images\"\n",
    "max_accuracy = 1000\n",
    "record_limiter = 5000\n",
    "\n",
    "def scrape_inaturalist_images(species_name):\n",
    "    \"\"\"Scrape images and metadata for a target species from iNaturalist.\"\"\"\n",
    "    # Fetch observations\n",
    "    observations = []\n",
    "    page = 1\n",
    "    per_page = 30  # Set a reasonable per_page value (e.g., 30, max=200)\n",
    "\n",
    "    # Iterate through paginated results until record_limiter is reached\n",
    "    while len(observations) < record_limiter:\n",
    "        response = get_observations(\n",
    "            taxon_id=species_name,\n",
    "            photos=True,\n",
    "            geo=True,\n",
    "            place_id=6753,\n",
    "            identified=True,\n",
    "            geoprivacy='open',\n",
    "            acc_below=max_accuracy,\n",
    "            page=page,\n",
    "            per_page=per_page\n",
    "        )\n",
    "\n",
    "        # Add observations from current page\n",
    "        observations.extend(response.get('results', []))\n",
    "\n",
    "        # Check if there are more pages or if we've reached the desired number of observations\n",
    "        if response.get('page') == response.get('pages') or len(observations) >= record_limiter:\n",
    "            break  # No more pages or enough observations collected\n",
    "\n",
    "        # Increment page for next iteration\n",
    "        page += 1\n",
    "\n",
    "    # Limit records to record_limiter if exceeded\n",
    "    observations = observations[:record_limiter]\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists and clear if not empty\n",
    "    if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "        for file in os.listdir(output_dir):\n",
    "            os.remove(os.path.join(output_dir, file))\n",
    "    else:\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Process observations and store metadata\n",
    "    metadata = []\n",
    "    for obs in observations:\n",
    "        observation_id = obs.get('id', None)\n",
    "        latitude = obs.get('geojson', {}).get('coordinates', [None, None])[1]\n",
    "        longitude = obs.get('geojson', {}).get('coordinates', [None, None])[0]\n",
    "        photos = obs.get('photos', [])\n",
    "\n",
    "        # Collect high-resolution photo URLs and IDs\n",
    "        photo_urls = [photo.get('url', \"\").replace(\"square\", \"original\") for photo in photos]\n",
    "        photo_ids = [photo.get('id', None) for photo in photos]\n",
    "\n",
    "        # Download and save photos\n",
    "        for i, img_url in enumerate(photo_urls):\n",
    "            try:\n",
    "                photo_id = photo_ids[i]\n",
    "                img_path = os.path.join(output_dir, f\"{photo_id}.jpg\")\n",
    "                with open(img_path, 'wb') as f:\n",
    "                    f.write(requests.get(img_url).content)\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading photo {photo_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Append metadata for the observation\n",
    "        metadata.append({\n",
    "            \"observation_id\": observation_id,\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"photo_ids\": photo_ids,  # List of photo IDs\n",
    "            \"photos\": photo_urls  # List of photo URLs\n",
    "        })\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlHZPoKpzO8N"
   },
   "source": [
    "# Use scraping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "executionInfo": {
     "elapsed": 733963,
     "status": "ok",
     "timestamp": 1737720271150,
     "user": {
      "displayName": "Pablo Deschepper",
      "userId": "11062026878236535060"
     },
     "user_tz": -60
    },
    "id": "c4IVi31wuq1F",
    "outputId": "651deb2e-b7b0-4b64-b141-830243ced4ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   observation_id   latitude  longitude    photo_ids  \\\n",
      "0       259414932  61.048887  14.443412  [465674164]   \n",
      "1       259341747  60.338892  28.577207  [465523509]   \n",
      "2       259323505  57.736160  10.629406  [465488543]   \n",
      "3       259194544  43.119729  -1.040918  [465223629]   \n",
      "4       259193935  48.037273  11.509971  [465220887]   \n",
      "\n",
      "                                              photos  \n",
      "0  [https://inaturalist-open-data.s3.amazonaws.co...  \n",
      "1  [https://inaturalist-open-data.s3.amazonaws.co...  \n",
      "2  [https://inaturalist-open-data.s3.amazonaws.co...  \n",
      "3  [https://inaturalist-open-data.s3.amazonaws.co...  \n",
      "4  [https://inaturalist-open-data.s3.amazonaws.co...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;36m1000\u001b[0m"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "species_name = \"30889\"\n",
    "metadata = scrape_inaturalist_images(species_name)\n",
    "\n",
    "# Convert metadata to a DataFrame for easier visualization\n",
    "df = pd.DataFrame(metadata)\n",
    "\n",
    "# Save metadata to a CSV file\n",
    "metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "df.to_csv(metadata_path, index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wscP1P_bwxvR"
   },
   "source": [
    "# Open a photo and check size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898,
     "output_embedded_package_id": "1VwqEyVL0ryO-ftXk1C0HCEl6zK19TN7T"
    },
    "executionInfo": {
     "elapsed": 3650,
     "status": "ok",
     "timestamp": 1737722307898,
     "user": {
      "displayName": "Pablo Deschepper",
      "userId": "11062026878236535060"
     },
     "user_tz": -60
    },
    "id": "JMIZ5flyyUPK",
    "outputId": "f11aa0be-599d-4ead-a3aa-72b214833ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = []\n",
    "for f in os.listdir(output_dir):\n",
    "    if os.path.isfile(os.path.join(output_dir, f)):\n",
    "        image_files.append(f)\n",
    "\n",
    "# Select a random image file\n",
    "random_image_file = random.choice(image_files)\n",
    "\n",
    "# Construct the full path to the random image\n",
    "random_image_path = os.path.join(output_dir, random_image_file)\n",
    "\n",
    "# Open the random image\n",
    "image = Image.open(random_image_path)\n",
    "\n",
    "# Get dimensions\n",
    "width, height = image.size\n",
    "print(f\"Width: {width}, Height: {height}\")\n",
    "\n",
    "# Display the image (optional)\n",
    "display(image)\n",
    "\n",
    "print(image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTK6Vm-rVy8V"
   },
   "source": [
    "# Zip photos (.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1737723424933,
     "user": {
      "displayName": "Pablo Deschepper",
      "userId": "11062026878236535060"
     },
     "user_tz": -60
    },
    "id": "8Ct4kplrU4Uw",
    "outputId": "d77ef116-9ed6-4325-ea52-b6a77fb90ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object _walk at 0x79304ec91a20>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_jpg_files(output_directory, zip_file_name=\"images.zip\"):\n",
    "    \"\"\"\n",
    "    This function zips all the .jpg files in a given directory.\n",
    "\n",
    "    Args:\n",
    "        output_directory: The directory where the .jpg files are located.\n",
    "        zip_file_name: The name of the zip file to be created (default: \"images.zip\").\n",
    "\n",
    "    Returns:\n",
    "        None. It creates a zip file in the output directory.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the full path for the zip file\n",
    "    zip_file_path = os.path.join(output_directory, zip_file_name)\n",
    "\n",
    "    # Open the zip file in write mode ('w')\n",
    "    with zipfile.ZipFile(zip_file_path, 'w') as zip_file:\n",
    "        # Go through all the files and folders in the output directory\n",
    "        for current_folder, subfolders, files in os.walk(output_directory):\n",
    "            # Check each file in the current folder\n",
    "            for file_name in files:\n",
    "                # If the file ends with '.jpg', add it to the zip file\n",
    "                if file_name.endswith('.jpg'):\n",
    "                    # Get the full path of the file\n",
    "                    file_path = os.path.join(current_folder, file_name)\n",
    "\n",
    "                    # Add the file to the zip file using its original name\n",
    "                    zip_file.write(file_path, arcname=file_name)\n",
    "\n",
    "    # Print a message to confirm the zip file creation\n",
    "    print(f\"All .jpg files in '{output_directory}' have been zipped to '{zip_file_name}'\")\n",
    "\n",
    "\n",
    "# Call the zip function\n",
    "zip_jpg_files(output_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUwx0SYS+P94ka9SboodpV",
   "mount_file_id": "1tQu3h38qBczfk6K_PVtK0MwEtZix7Ic3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
